# -*- coding: utf-8 -*-
"""DeepFashionModelVGG16.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dIVk--Hl-eBgKPmJpt68zZ8PTl5gVAtn
"""

from tensorflow.keras.applications import vgg16
from keras.applications.vgg16 import VGG16
import keras
from keras.layers import Conv2D,Dense,MaxPooling2D,Dropout,Flatten, Activation, BatchNormalization,LeakyReLU
from keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import pandas as pd
import cv2
import glob
from keras.utils import plot_model

#Inserting all images path into a list
def read_img_file_name(path, class_lables):
  images = []
  for class_lable in class_lables:
    images.append(glob.glob(path + class_lable + '/*.jpg'))
  images = [val for sublist in images for val in sublist]
  return images

# Creating the model architecture
# Building the model & Compile
def build_model(vgg_conv, num_topics, drop_rate, learning_rate, momentum_num):
  # Create the model
  model = keras.models.Sequential()

  # Add the vgg convolutional base model
  model.add(vgg_conv)

  # Add new layers
  model.add(Flatten())
  model.add(Dense(1024, activation='relu'))
  model.add(BatchNormalization())
  model.add(Dropout(drop_rate))
  model.add(Dense(num_topics, activation='softmax'))

  # Compile the model with a SGD and a very slow learning rate
  model.compile(loss='binary_crossentropy',
                #optimizer=keras.optimizers.SGD(lr=learning_rate, momentum=momentum_num),
                optimizer = keras.optimizers.adam(learning_rate=learning_rate),
                metrics=['accuracy'])
                
  return model

# Data augmentation
def data_aug(train_path, validation_path, batch_size,batch_size_val, shift_fraction, img_r, img_c):
  gen = ImageDataGenerator(
          rescale=1./255,
          height_shift_range=shift_fraction,
          width_shift_range=shift_fraction,
          shear_range=shift_fraction,
          zoom_range=shift_fraction,
          horizontal_flip=True,
          vertical_flip=True)

  val_gen = ImageDataGenerator(rescale=1./255)

  batches = gen.flow_from_directory(train_path,
          target_size=(img_r, img_c),
          batch_size=batch_size,
          class_mode='categorical',
          shuffle=True)
  val_batches = val_gen.flow_from_directory(validation_path,
          target_size=(img_r, img_c),
          batch_size=batch_size_val,
          class_mode='categorical',
          shuffle=False)
  return batches, val_batches

# Fine-tune the model - Training 
def fit_model(model, batches, val_batches, batch_size,batch_size_val,epochs):
  history = model.fit_generator(batches, steps_per_epoch=len(batches.filenames)//batch_size, epochs=epochs,validation_data=val_batches,
                                                    validation_steps=len(val_batches.filenames)//batch_size_val
                                ,max_queue_size=8, workers=4)
  score = model.evaluate_generator(val_batches,steps=len(val_batches.filenames)//batch_size_val, verbose=0)
  return model, history, score

# Plotting Accuracy & Loss Curves
def curves(model_histories, epochs):
  acc = model_histories.history['accuracy']
  val_acc = model_histories.history['val_accuracy']
  loss = model_histories.history['loss']
  val_loss = model_histories.history['val_loss']
  # Plots
  plt.plot(range(epochs), acc, 'mo', label='Training accuracy')
  plt.plot(range(epochs), val_acc, 'b', label='Validation accuracy')
  plt.title('Training and validation accuracy')
  plt.legend()
  plt.savefig('/content/drive/My Drive/FashionAI/DeepFashionVGG16CurvesAcc.jpg')

  plt.figure()
  plt.plot(range(epochs), loss, 'mo', label='Training loss')
  plt.plot(range(epochs), val_loss, 'b', label='Validation loss')
  plt.title('Training and validation loss')
  plt.legend()
  plt.savefig('/content/drive/My Drive/FashionAI/DeepFashionVGG16CurvesLoss.jpg')
  plt.show()

#Confusion Matrix and Classification Report
def confusion_mat(model,Y_pred, testY_labels, class_labels):
  y_pred = np.argmax(Y_pred, axis=1)
  confusion_mat = confusion_matrix(testY_labels, y_pred)
  classification_rep = classification_report(testY_labels, y_pred, target_names=class_labels)
  plt.figure(figsize=(6,4))
  df_confusion_mat = pd.DataFrame(confusion_mat)
  sns.heatmap(df_confusion_mat, annot_kws={"size": 10}, linewidths=.5, cmap='PuBu', annot=True,
            yticklabels=class_labels, xticklabels=class_labels, fmt='g')
  plt.xticks(rotation=40) 
  plt.ylabel('True label')
  plt.xlabel('Predicted label')
  plt.savefig('/content/drive/My Drive/FashionAI/DeepFashionVGG16_confusion_matrix.jpg')
  return  plt, classification_rep

def plot_image(i, predictions_array, true_label, img, class_labels):
  img = cv2.imread(img[i])
  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  predictions_array, true_label, img = predictions_array, true_label[i], img
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])
  plt.imshow(img)
  predicted_label = np.argmax(predictions_array)
  if predicted_label == true_label:
    color = 'lightseagreen'
  else:
    color = 'crimson'
  plt.xlabel("{} {:2.0f}% ({})".format(class_labels[predicted_label],
                                100*np.max(predictions_array),
                                class_labels[true_label]),
                                color=color,fontsize=10)

def predicted_imgs(Y_pred, testY_labels, testX_img, class_labels, plt_num_rows, plt_num_cols):
  num_images = plt_num_rows*plt_num_cols
  plt.figure(figsize=(2*2*plt_num_cols, 2*plt_num_rows))
  for i in range(num_images):
    plt.subplot(plt_num_rows, 2*plt_num_cols, 2*i+1)
    plot_image(i, Y_pred[i], testY_labels, testX_img, class_labels)
  plt.savefig('/content/drive/My Drive/FashionAI/DeepFashionVGG16_predicted_imgs.jpg')
  plt.show()

def presenting_imgs_example(path, plt_num_rows, plt_num_cols):
  images = glob.glob(path + '/*.jpg')
  num_images = plt_num_rows*plt_num_cols
  plt.figure(figsize=(plt_num_cols, plt_num_rows))
  for i in range(num_images):
    plt.subplot(plt_num_rows, plt_num_cols, i+1)
    img = cv2.imread(images[i])
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
   # true_label = true_label[i]
   # plt.xlabel(class_labels[true_label], color=color,fontsize=10)
    plt.grid(False)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(img)
    plt.savefig('/content/drive/My Drive/FashionAI/DeepFashionVGG16_presenting_imgs.jpg')
  plt.show()

#Drive data
#from google.colab import drive
#drive.mount('/content/drive')
example_images_path = "/content/drive/My Drive/FashionAI/example_images/"
train_path = "/content/drive/My Drive/FashionAI/images/train/"
validation_path = "/content/drive/My Drive/FashionAI/images/validation/"

# Setting the Parameters & Hyperparameters
IMG_R, IMG_C = 224, 224
BS = 30
BS_VAL = 21
EPOCHS = 45
NUM_TOPICS = 3
DROP_RATE = 0.25
SHIFT_FRACTION=0.2 
LR = 1e-5
MOMENTUM_NUM = 0.99
PLT_NUM_ROWS = 3
PLT_NUM_COLS = 3

# Initialize the VGG model
vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_R, IMG_C, 3))

# Freeze all the layers
for layer in vgg_conv.layers[:]:
    layer.trainable = False

# Check the trainable status of the individual layers
for layer in vgg_conv.layers:
    print(layer, layer.trainable)

# Creating the model Architecture
model = build_model(vgg_conv, NUM_TOPICS, DROP_RATE, LR, MOMENTUM_NUM)
# Show a summary of the model
plot_model(model, to_file='/content/drive/My Drive/FashionAI/model_summary.jpg')

batches, val_batches = data_aug(train_path, validation_path, BS,BS_VAL, SHIFT_FRACTION, IMG_R, IMG_C)

# Reading images paths from directory
presenting_imgs_example(example_images_path, PLT_NUM_ROWS, PLT_NUM_COLS)

model, histories, score = fit_model(model, batches, val_batches, BS, BS_VAL, EPOCHS)

# Learning curves
curves(histories, EPOCHS)

print('Accuracy:{} \nLoss:{}'.format(score[1] ,score[0]))

CLASS_LABELS = list(val_batches.class_indices.keys())
testY_labels = val_batches.labels
num_imgs_val = len(val_batches.filenames)
num_imgs_train = len(batches.filenames)

# Prediction
Y_pred = model.predict_generator(val_batches,steps=len(val_batches.filenames)//BS_VAL)

confusion_mat, classification_rep = confusion_mat(model,Y_pred, testY_labels, CLASS_LABELS)

print(classification_rep)

# Reading images paths from validation directory
img_name = read_img_file_name(validation_path, CLASS_LABELS)

# Ploting test images with their predicted labels and the true labels.
predicted_imgs(Y_pred, testY_labels, img_name, CLASS_LABELS, PLT_NUM_ROWS, PLT_NUM_COLS)

# Save the model
model.save('/content/drive/My Drive/FashionAI/DeepFashionModelVGG16')
model.save_weights('/content/drive/My Drive/FashionAI/DeepFashionModelVGG16_weights.h5')